

# **LoadMore Web Scraper** ğŸš€  
A **Selenium & BeautifulSoup-based web scraper** that automates **dynamic content extraction** from websites with "Load More" buttons. This script continuously **clicks the button, scrapes article details, and stores them** in an Excel file, ensuring **incremental backups** to prevent data loss.  

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/DataDiggerJay/Loadmore-Web-scrapper)  
  

## **ğŸ“Œ Features**  

âœ… **Automated Scrolling & Clicking** â€“ Handles infinite scrolling & dynamic "Load More" buttons.  
âœ… **Customizable Target Website** â€“ Modify `TARGET_URL` to scrape different blogs or news sites.  
âœ… **Data Backup & Export** â€“ Saves data incrementally in CSV & outputs the final data in Excel.  
âœ… **Headless Mode** â€“ Runs in the background without opening a browser.  
âœ… **Efficient & Scalable** â€“ Prevents infinite loops with a click limit (`MAX_CLICKS`).  

---

## **ğŸ“‚ Project Structure**  
```
ğŸ“¦ Loadmore-Web-Scraper
â”‚â”€â”€ ğŸ“„ scraper.py          # Main Python script for scraping
â”‚â”€â”€ ğŸ“„ requirements.txt    # List of dependencies
â”‚â”€â”€ ğŸ“„ README.md           # Project documentation
â”‚â”€â”€ ğŸ“„ scraped_articles.xlsx  # Final extracted data (Generated after running the script)
```

---

## **ğŸ”§ Setup & Installation**  

### **1ï¸âƒ£ Clone the Repository**  
```sh
git clone https://github.com/DataDiggerJay/Loadmore-Web-scrapper.git
cd Loadmore-Web-scrapper
```

### **2ï¸âƒ£ Install Dependencies**  
Ensure you have Python **3.7+** installed. Then, run:  
```sh
pip install -r requirements.txt
```

### **3ï¸âƒ£ Run the Scraper**  
Simply execute the script:  
```sh
python scraper.py
```
It will launch a **headless browser**, scrape articles, and store data in an **Excel file (`scraped_articles.xlsx`)**.

---

## **ğŸ›  Customization Guide**  

ğŸ”¹ **Change Target Website:** Modify the `TARGET_URL` variable in `scraper.py`.  
ğŸ”¹ **Scrape Different Data:** Adjust the BeautifulSoup selectors to capture other elements.  
ğŸ”¹ **Adjust Load More Clicks:** Change `MAX_CLICKS` to control how much data is scraped.  
ğŸ”¹ **Enable Browser View:** Remove the `--headless` option in Selenium settings.  

---

## **ğŸ“Š Example Output (Excel File)**  
| Title | href | Original Link |
|--------|------|--------------|
| Example Blog Post 1 | https://example.com/post1 | https://example.com/post1 |
| Example Blog Post 2 | https://example.com/post2 | https://example.com/post2 |

---

## **ğŸ“œ License**  
This project is **MIT Licensed** â€“ feel free to modify and use it for your own projects! ğŸ¯  

---

## **ğŸ¤ Contributing**  
Pull requests and improvements are welcome! Feel free to:  
âœ… Report Issues  
âœ… Add Features  
âœ… Improve Documentation  

---

## **ğŸŒŸ Show Your Support**  
If you found this project useful, please **â­ Star this repository** and **Share it** with others! ğŸš€  

---

Happy Scraping! ğŸ•µï¸â€â™‚ï¸ğŸ’»  

---
